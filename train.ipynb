{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18zf08giXH3kxa5ZeVxip2k6loUaV1SV-",
      "authorship_tag": "ABX9TyM9/osqyf8G3BwolKBZmJlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritesh604/AVMLA_Project_IAE/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aLuKJQEkdFp"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/AVMLA_Project_IAE') "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxAlzouoKNt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from preprocess import Preprocessor\n",
        "from yolov3 import YoloV3\n",
        "from postprocess import Postprocessor\n",
        "\n",
        "num_classes = 3\n",
        "class_names= ['Cyclist','Car','Pedestrain']\n",
        "dest_path = \"/content/drive/MyDrive/AVMLA_Project_IAE/detection_result\" \n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyJnfX__Pbvu"
      },
      "source": [
        "#!pip install tensorflow==2.0.0\n",
        "#!pip install tensorflow==1.13.2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSr-J84mDJz",
        "outputId": "9b2afda6-7934-4fc4-e74b-11b19aeaeb67"
      },
      "source": [
        "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzcwhBFkkqdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b61fc9-d1c5-4128-ccb8-783392b5d264"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-01 21:28:06.068781: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-10-01 21:28:06.089202: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-10-01 21:28:06.089562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c64746cbc0 executing computations on platform Host. Devices:\n",
            "2021-10-01 21:28:06.089608: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:There is non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "bboxes Tensor(\"stack:0\", shape=(None, 4), dtype=float32)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "bboxes Tensor(\"stack:0\", shape=(None, 4), dtype=float32)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(), dtype=string)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 416, 416, 5) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "darknet_53 (Model)              ((None, 52, 52, 256) 40621216    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_1_conv (None, 13, 13, 512)  524288      darknet_53[1][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_1_bn ( (None, 13, 13, 512)  2048        detector_scale_large_1x1_1_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_1_leak (None, 13, 13, 512)  0           detector_scale_large_1x1_1_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_1_conv (None, 13, 13, 1024) 4718592     detector_scale_large_1x1_1_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_1_bn ( (None, 13, 13, 1024) 4096        detector_scale_large_3x3_1_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_1_leak (None, 13, 13, 1024) 0           detector_scale_large_3x3_1_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_2_conv (None, 13, 13, 512)  524288      detector_scale_large_3x3_1_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_2_bn ( (None, 13, 13, 512)  2048        detector_scale_large_1x1_2_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_2_leak (None, 13, 13, 512)  0           detector_scale_large_1x1_2_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_2_conv (None, 13, 13, 1024) 4718592     detector_scale_large_1x1_2_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_2_bn ( (None, 13, 13, 1024) 4096        detector_scale_large_3x3_2_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_2_leak (None, 13, 13, 1024) 0           detector_scale_large_3x3_2_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_3_conv (None, 13, 13, 512)  524288      detector_scale_large_3x3_2_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_3_bn ( (None, 13, 13, 512)  2048        detector_scale_large_1x1_3_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_1x1_3_leak (None, 13, 13, 512)  0           detector_scale_large_1x1_3_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_0_con (None, 13, 13, 256)  131072      detector_scale_large_1x1_3_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_0_bn  (None, 13, 13, 256)  1024        detector_scale_medium_1x1_0_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_0_lea (None, 13, 13, 256)  0           detector_scale_medium_1x1_0_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_1_upsampling (Up (None, 26, 26, 256)  0           detector_scale_medium_1x1_0_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_1_concat (Concat (None, 26, 26, 768)  0           detector_scale_1_upsampling[0][0]\n",
            "                                                                 darknet_53[1][1]                 \n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_1_con (None, 26, 26, 256)  196608      detector_scale_1_concat[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_1_bn  (None, 26, 26, 256)  1024        detector_scale_medium_1x1_1_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_1_lea (None, 26, 26, 256)  0           detector_scale_medium_1x1_1_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_1_con (None, 26, 26, 512)  1179648     detector_scale_medium_1x1_1_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_1_bn  (None, 26, 26, 512)  2048        detector_scale_medium_3x3_1_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_1_lea (None, 26, 26, 512)  0           detector_scale_medium_3x3_1_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_2_con (None, 26, 26, 256)  131072      detector_scale_medium_3x3_1_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_2_bn  (None, 26, 26, 256)  1024        detector_scale_medium_1x1_2_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_2_lea (None, 26, 26, 256)  0           detector_scale_medium_1x1_2_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_2_con (None, 26, 26, 512)  1179648     detector_scale_medium_1x1_2_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_2_bn  (None, 26, 26, 512)  2048        detector_scale_medium_3x3_2_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_2_lea (None, 26, 26, 512)  0           detector_scale_medium_3x3_2_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_3_con (None, 26, 26, 256)  131072      detector_scale_medium_3x3_2_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_3_bn  (None, 26, 26, 256)  1024        detector_scale_medium_1x1_3_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_1x1_3_lea (None, 26, 26, 256)  0           detector_scale_medium_1x1_3_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_0_conv (None, 26, 26, 128)  32768       detector_scale_medium_1x1_3_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_0_bn ( (None, 26, 26, 128)  512         detector_scale_small_1x1_0_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_0_leak (None, 26, 26, 128)  0           detector_scale_small_1x1_0_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_upsampling (None, 52, 52, 128)  0           detector_scale_small_1x1_0_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_concat (Co (None, 52, 52, 384)  0           detector_scale_small_upsampling[0\n",
            "                                                                 darknet_53[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_1_conv (None, 52, 52, 128)  49152       detector_scale_small_concat[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_1_bn ( (None, 52, 52, 128)  512         detector_scale_small_1x1_1_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_1_leak (None, 52, 52, 128)  0           detector_scale_small_1x1_1_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_1_conv (None, 52, 52, 256)  294912      detector_scale_small_1x1_1_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_1_bn ( (None, 52, 52, 256)  1024        detector_scale_small_3x3_1_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_1_leak (None, 52, 52, 256)  0           detector_scale_small_3x3_1_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_2_conv (None, 52, 52, 128)  32768       detector_scale_small_3x3_1_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_2_bn ( (None, 52, 52, 128)  512         detector_scale_small_1x1_2_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_2_leak (None, 52, 52, 128)  0           detector_scale_small_1x1_2_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_2_conv (None, 52, 52, 256)  294912      detector_scale_small_1x1_2_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_2_bn ( (None, 52, 52, 256)  1024        detector_scale_small_3x3_2_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_2_leak (None, 52, 52, 256)  0           detector_scale_small_3x3_2_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_3_conv (None, 52, 52, 128)  32768       detector_scale_small_3x3_2_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_3_bn ( (None, 52, 52, 128)  512         detector_scale_small_1x1_3_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_1x1_3_leak (None, 52, 52, 128)  0           detector_scale_small_1x1_3_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_3_conv (None, 52, 52, 256)  294912      detector_scale_small_1x1_3_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_3_con (None, 26, 26, 512)  1179648     detector_scale_medium_1x1_3_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_3_conv (None, 13, 13, 1024) 4718592     detector_scale_large_1x1_3_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_3_bn ( (None, 52, 52, 256)  1024        detector_scale_small_3x3_3_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_3_bn  (None, 26, 26, 512)  2048        detector_scale_medium_3x3_3_conv2\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_3_bn ( (None, 13, 13, 1024) 4096        detector_scale_large_3x3_3_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_3x3_3_leak (None, 52, 52, 256)  0           detector_scale_small_3x3_3_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_3x3_3_lea (None, 26, 26, 512)  0           detector_scale_medium_3x3_3_bn[0]\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_3x3_3_leak (None, 13, 13, 1024) 0           detector_scale_large_3x3_3_bn[0][\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_small_final_conv (None, 52, 52, 24)   6168        detector_scale_small_3x3_3_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_medium_final_con (None, 26, 26, 24)   12312       detector_scale_medium_3x3_3_leaky\n",
            "__________________________________________________________________________________________________\n",
            "detector_scale_large_final_conv (None, 13, 13, 24)   24600       detector_scale_large_3x3_3_leakyr\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape (TensorFlowOp [(4,)]               0           detector_scale_small_final_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape_1 (TensorFlow [(4,)]               0           detector_scale_medium_final_conv2\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape_2 (TensorFlow [(4,)]               0           detector_scale_large_final_conv2d\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [()]                 0           tf_op_layer_Shape[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_6 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_7 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_8 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_sm [(5,)]               0           tf_op_layer_strided_slice[0][0]  \n",
            "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_me [(5,)]               0           tf_op_layer_strided_slice_3[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_4[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_la [(5,)]               0           tf_op_layer_strided_slice_6[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_7[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_8[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_sm [(None, None, None,  0           detector_scale_small_final_conv2d\n",
            "                                                                 tf_op_layer_detector_reshape_smal\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_me [(None, None, None,  0           detector_scale_medium_final_conv2\n",
            "                                                                 tf_op_layer_detector_reshape_meid\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_detector_reshape_la [(None, None, None,  0           detector_scale_large_final_conv2d\n",
            "                                                                 tf_op_layer_detector_reshape_larg\n",
            "==================================================================================================\n",
            "Total params: 61,587,688\n",
            "Trainable params: 61,535,080\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "20211001-212816 Start training...\n",
            "20211001-212816 Started epoch 1 with learning rate 0.01. Current LR patience count is 1 epochs. Last lowest val loss is inf.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\n",
            "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 902, in wrapper\n",
            "    ), args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/impl/api.py\", line 539, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/tmpc08cc521.py\", line 39, in tf__distributed_train_epoch\n",
            "    total_loss, num_train_batches = ag__.for_stmt(dataset, None, loop_body, get_state, set_state, (total_loss, num_train_batches), ('total_loss', 'num_train_batches'), ())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py\", line 337, in for_stmt\n",
            "    return custom_handler(extra_test, body, init_vars)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/input_lib.py\", line 408, in _autograph_for_loop\n",
            "    return self.reduce(init_state, reduce_body)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/input_lib.py\", line 445, in reduce\n",
            "    cond, loop_body, [has_data, data, initial_state], parallel_iterations=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 2675, in while_loop\n",
            "    back_prop=back_prop)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/while_v2.py\", line 295, in while_loop\n",
            "    name=scope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_functional_ops.py\", line 1104, in _while\n",
            "    parallel_iterations=parallel_iterations, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 471, in _apply_op_helper\n",
            "    as_ref=input_arg.is_ref)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1365, in internal_convert_n_to_tensor\n",
            "    ctx=ctx))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1266, in internal_convert_to_tensor\n",
            "    return graph.capture(value, name=name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 591, in capture\n",
            "    return self._capture_helper(tensor, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 612, in _capture_helper\n",
            "    tensor, name=name, dtype=tensor.dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 1055, in _create_substitute_placeholder\n",
            "    custom_gradient.copy_handle_data(value, placeholder)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/custom_gradient.py\", line 71, in copy_handle_data\n",
            "    handle_data.SerializeToString())\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 322, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 318, in main\n",
            "    trainer.run(train_dist_dataset, val_dist_dataset)\n",
            "  File \"train.py\", line 216, in run\n",
            "    train_dist_dataset, train_summary_writer, total_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializer_map)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/func_graph.py\", line 956, in func_graph_from_py_func\n",
            "    func_graph.variables = variables\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/auto_control_deps.py\", line 300, in __exit__\n",
            "    if op.type == \"Switch\" and op.inputs[0].dtype == dtypes_module.resource:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 2259, in type\n",
            "    return c_api.TF_OperationOpType(self._c_op)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnqVlJEnnyMf"
      },
      "source": [
        "import glob\n",
        "TF_RECORDS = r'/content/drive/MyDrive/Raw_data/Raw_data_pickle/Train_dataset/*.tfrecords'\n",
        "x =glob.glob(TF_RECORDS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tWoE7bMsJXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c4e766-96b0-4ba6-b0f9-20c386deaecb"
      },
      "source": [
        "classes =tf.Variable(['Car','Pedestrain','Cyclist'],dtype = 'string')\n",
        "classes.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'Car', b'Pedestrain', b'Cyclist'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q5qkYID0cFn"
      },
      "source": [
        "class_list=tf.TensorArray(tf.int32, size=0,dynamic_size=True)\n",
        "classes =tf.constant(['Car','Pedestrain','Cyclist','Cyclist'],dtype = 'string')\n",
        "i=0\n",
        "for j in classes:\n",
        "            \n",
        "            if j == 'Car':\n",
        "                class_list = class_list.write(class_list.size(),0)\n",
        "                \n",
        "            elif j == 'Cyclist':\n",
        "                class_list = class_list.write(class_list.size(),1)\n",
        "                \n",
        "            else :\n",
        "                class_list = class_list.write(class_list.size(),2)\n",
        "                \n",
        "            classes_oh = tf.one_hot(class_list.stack(),num_classes)i=0\n",
        "        for j in classes:\n",
        "            \n",
        "            if j == 'Car':\n",
        "                class_list = class_list.write(class_list.size(),0)\n",
        "                \n",
        "            elif j == 'Cyclist':\n",
        "                class_list = class_list.write(class_list.size(),1)\n",
        "                \n",
        "            else :\n",
        "                class_list = class_list.write(class_list.size(),2)\n",
        "                \n",
        "               \n",
        "        classes_oh = tf.one_hot(class_list.stack(),num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJz8FKrE3JrB",
        "outputId": "e89b5923-8891-4a66-a43a-d0af381ce3be"
      },
      "source": [
        "classes_oh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jv2Fx9wSI2Q"
      },
      "source": [
        "def _find_single_predestrain(txt):\n",
        "  classes =[]\n",
        "  f = open(txt,'r')\n",
        "  lines= f.readlines()\n",
        "  for line in lines:\n",
        "    if (line.split(',')[0]) in ['0.0','1.0','2.0']:\n",
        "           if line.split(',')[0] == '0.0':\n",
        "              classes.append(bytes('Cyclist','utf-8'))\n",
        "           elif line.split(',')[0] == '1.0':\n",
        "              classes.append(bytes('Car','utf-8'))\n",
        "           elif line.split(',')[0] == '2.0':\n",
        "              classes.append(bytes('Pedestrain','utf-8'))  \n",
        "  #print(classes)\n",
        "  if len(classes) ==1 and classes[0]==b'Pedestrain' :\n",
        "       print(txt)         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWtSulHg6dYr"
      },
      "source": [
        "# import glob\n",
        "# txt = glob.glob(r'/content/drive/MyDrive/Raw_data/Raw_data_bounding_box/Train_dataset/*.txt')\n",
        "\n",
        "# for tx in txt:\n",
        "#   _find_single_predestrain(tx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELdKE6sLRRb4",
        "outputId": "47d92796-f380-4554-80b9-8440d4f39c4b"
      },
      "source": [
        "classes  = [2,5,6]\n",
        "print(len(classes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJRFJy0xtrQ4"
      },
      "source": [
        "\n",
        "def Read_text(text):\n",
        "   classes=[];xmins=[];xmaxs=[];ymins=[];ymaxs=[]\n",
        "   f = open(text,'r')\n",
        "   lines= f.readlines()\n",
        "   for line in lines:\n",
        "       #print('x')\n",
        "       if (line.split(',')[0]) in ['0.0','1.0','2.0']:\n",
        "           if line.split(',')[0] == '0.0':\n",
        "              classes.append(bytes('Cyclist','utf-8'))\n",
        "           elif line.split(',')[0] == '1.0':\n",
        "              classes.append(bytes('Car','utf-8'))\n",
        "           elif line.split(',')[0] == '2.0':\n",
        "              classes.append(bytes('Pedestrain','utf-8'))  \n",
        "           #classes.append(int(float(line.split(',')[0])))\n",
        "           xmins.append(float(line.split(',')[1]))\n",
        "           ymins.append(float(line.split(',')[2]))\n",
        "           xmaxs.append(float(line.split(',')[3]))\n",
        "           ymaxs.append(float(line.split(',')[4]))\n",
        "   #print(classes)    \n",
        "      \n",
        "   return  classes,xmins,ymins,xmaxs,ymaxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAs4hK5GuS7j"
      },
      "source": [
        "classes = []\n",
        "xmins=[] \n",
        "ymins=[]\n",
        "xmaxs=[]\n",
        "ymaxs=[]\n",
        "for i in range(len(txt)):\n",
        "  classe,xmin,ymin,xmax,ymax = Read_text(txt[i])\n",
        "  for x in xmin:\n",
        "    x= int(x)\n",
        "    if x<0:\n",
        "      print(txt[i])\n",
        "  for y in ymin:\n",
        "    y = int(y)\n",
        "    if y<0 :\n",
        "      print(txt[i])   \n",
        "\n",
        "  # classes.append(classe)\n",
        "\n",
        "  # xmins.append(xmin)\n",
        "  # ymins.append(ymin)\n",
        "  # xmaxs.append(xmax)\n",
        "  # ymaxs.append(ymax)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVSVRCiYxHge"
      },
      "source": [
        "classes = []\n",
        "xmins=[] \n",
        "ymins=[]\n",
        "xmaxs=[]\n",
        "ymaxs=[]\n",
        "for i in range(len(txt)):\n",
        "  classes,xmin,ymin,xmax,ymax = Read_text(txt[i])\n",
        "  for class_ in classes:\n",
        "    \n",
        "    if not class_  in [b'Car',b'Cyclist',b'Pedestrain']:\n",
        "      print(txt[i]) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyWSO1rW5hWx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "67583c11-d7fe-4ee5-8949-399b23a8e1f6"
      },
      "source": [
        "classes = ['Car']\n",
        "tf.sparse.to_dense(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b5ed64b0102a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Car'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36msparse_tensor_to_dense\u001b[0;34m(sp_input, default_value, validate_indices, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m   \"\"\"\n\u001b[0;32m-> 1711\u001b[0;31m   \u001b[0msp_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdefault_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[0mdefault_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/sparse_ops.py\u001b[0m in \u001b[0;36m_convert_to_sparse_tensor\u001b[0;34m(sp_input)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a SparseTensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msp_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input must be a SparseTensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmmeTaY0Zb9W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}